Ce projet contient trois tâches de classification d'apprentissage automatique de texte:

### Classification des sentiments sur Twitter en français


L'ensemble de données provient de [Kaggle](https://www.kaggle.com/datasets/hbaflast/french-twitter-sentiment-analysis).C’est un ensemble de données français avec les étiquettes pour l'analyse des sentiments (données traduites de l'anglais vers le français.)Il s'agit d'un ensemble de données qui est stocké dans un fichier csv, il y a 2 classes, un commentaire Twitter est une instance ,donc sur un total de 1 526 724 instances, les mots de ces instances totalisent 252 741 mots, et deux classes : positif (valeur 1) et négatif (valeur 0) dans l'ensemble de données. 

### Multi-classification de quinze catégories fines

L'ensemble de données provient de [Kaggle](https://www.kaggle.com/datasets/nltkdata/brown-corpus).
Le type d'ensemble de données est un fichier csv, qui contient 15 classes：adventure, belles_lettres, editorial, fiction, government, hobbies, humor, learned, lore, mystery, news, religion, reviews, romance, science_fiction. Il y a un total de 57 340 textes, et le nombre de mots sans doublon dans l'ensemble des données est de 55 982. Ce dataset contient du texte avec des annotations POS et du texte brut, je comparerai les résultats des tests formés par ces deux ensembles de texte.

### Multi-classification de trois grandes catégories 
Ce jeu de données est directement importé du module NLTK, donc le jeu de données est différent du marron ci-dessus, il a une taille plus petite et moins d'étiquettes. Il y a un total de 309 textes (instances) dans cet ensemble de données, qui sont divisés en 9 classes : editorial, reviews, news, adventure, mystery, fiction, romance, learned, government. 

Je les reclasse directement en trois grandes catégories: news=[editorial, reviews, news], books=[adventure, mystery, fiction, romance], sciences=[learned, government].Dans la catégorie news, il y a 88 documents avec 202 862 mots, dans la catégorie books, il y a 111 documents avec un total de 265 021 mots et dans la catégorie sciences, il y a 110 documents avec un total de 252 005 mots.

## Méthodologie
Afin d'obtenir un modèle avec une grande précision et une compréhension plus approfondie de divers paramètres de chaque algorithme, je vais ajuster divers paramètres dans les fonctions des classificateurs et effectuer différents pré-traitements sur les données de texte. En général, je ferai quatre plans pour chaque ensemble de données : 1. Utiliser le texte brut, 2. Transformer les lettres en minuscules 3. Supprimer les mots vides 4. Transformer les lettres en minuscules et supprimer les mots vides. Pour les textes anglais et français, j'ai utilisé les listes de mots vides correspondantes.

Avant de former un classificateur d'apprentissage automatique, il y a un problème qui doit être résolu, et c'est l'extraction de caractéristiques. Les ordinateurs ne comprennent pas le texte comme nous, ils ne comprennent que les 0 et les 1. Par conséquent, la première étape de la formation d'un classificateur TAL consiste à convertir le texte en une représentation vectorielle numérique. L'une des méthodes d'incorporation de texte les plus couramment utilisées est le sac de mots, ce modèle considère le texte comme un ensemble de mots multiples et non ordonnés, indépendamment de la grammaire et de l'ordre des mots. Il peut également être considéré comme un modèle d'espace vectoriel dont le mot est l'unité de base. Cependant, dans des scénarios pratiques, l'ordre des mots est très important et peut affecter le sens d'une phrase. Par conséquent, nous devons préserver l'ordre des mots dans les caractéristiques. Avec une collection de N caractéristiques, le texte peut être représenté comme un vecteur en utilisant le modèle du sac de mots. Au fur et à mesure que N augmente, le nombre de caractéristiques qui peuvent être extraites augmente de façon exponentielle, et l'espace des caractéristiques augmente de façon exponentielle. La fréquence de ces caractéristiques d'ordre supérieur est également relativement faible, ce qui n'est pas très utile pour la classification et affecte directement l'efficacité et la complexité du traitement ultérieur. Par conséquent, pour les tâches générales de classification de texte, N de 3 est suffisant, et les caractéristiques binaires et monadiques sont utilisées pour éviter l'ajustement excessif. Donc, j'utiliserai Unigram, Bi-gram et Tri-gram pour extraire des caractéristiques et générer des vecteurs à partir des données textuelles en utilisant différentes méthodes de pré-traitement.

Une fois que les représentations vectorielles de tous les documents texte étiquetés sont générées, elles peuvent être utilisées pour former un classificateur. Un vecteur de documents texte est transmis au classificateur avec la catégorie correcte. Une fois que le modèle est formé pour répondre aux critères de performance requis, il peut être utilisé pour faire des prédictions précises. La même méthode d'extraction de caractéristiques est utilisée pour créer des représentations vectorielles de nouveaux documents texte, puis les modèles de classification utilisent ces vecteurs de caractéristiques pour prédire la catégorie du document.

J'ai importé sept modèles d'algorithmes d'apprentissage automatique de sklearn, à savoir : Perceptron, MultinomialNB, LogisticRegression, LinearSVC, DecisionTreeClassifier, RandomForestClassifier et Perceptron multicouche. Pour les paramétrages de chaque classificateur, je les ai modifiés un par un à l'avance jusqu'à ce que les meilleurs paramétrages du modèle pour ces données soient testés. Par contre, je n'ai pas utilisé Decision tree et Perceptron Multicouche dans le corpus Twitter, ses données de 2 et 3 gramme sont trop volumineuses, j'ai attendu 678 minutes et il n'est toujours pas sorti, et d'après le test de ce modèle sur d'autres données, ses performances ne sont pas très exceptionnelles, alors j’ai les abandonné. Parmi les différents classificateurs bayésiens, le Bayésien Multinomial est le plus adapté au traitement de texte, c'est pourquoi je l'ai choisi. Avant la tâche, je pense que les arbres de décision et les forêts aléatoires peuvent ne pas être très adaptés à la classification de texte, surtout pour les données de texte  qui ont un somme considérable, puis à la fin je peux vérifier si mon hypothèse est correcte.

Pour mesurer les performances de chaque classificateur, j’ai importé classification_report de sklearn.metrics pour voir la relation entre les prédictions du classificateur et les résultats réels, également j'enregistré le temps qu'il met à s'exécuter.
